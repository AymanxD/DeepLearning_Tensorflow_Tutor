{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "data = fetch_olivetti_faces(shuffle = True)\n",
    "labels = LabelBinarizer().fit_transform(data.target)\n",
    "\n",
    "# Training Data\n",
    "images_DataTraining = data.data[0:299]\n",
    "labels_DataTraining = labels[0:299]\n",
    "\n",
    "# Validation Data\n",
    "images_DataValidation = data.data[299:349]\n",
    "labels_DataValidation = labels[299:349]\n",
    "\n",
    "# Testing Data\n",
    "images_DataTesting = data.data[349:399]\n",
    "labels_DataTesting = labels[349:399]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution and Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Layer -> 1st Convolutional Layer -> 1st Pooling Layer -> 2nd Convolutional Layer -> 2nd Pooling Layer -> 3rd Convolutional Layer -> 3rd Pooling Layer -> Fully Connected Layer -> Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4096)\n",
      "(?, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 4096])\n",
    "y_ = tf.placeholder(tf.float32, [None, 40])\n",
    "\n",
    "# Add function to create weight variable \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Add function to create bias variable \n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Add convolution function\n",
    "def conv2d(x, W):\n",
    "    return(tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = \"SAME\"))\n",
    "\n",
    "# Add Pooling function\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = \"SAME\")\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "# Reshape the data for inputting it in the input layer\n",
    "x_image = tf.reshape(x, [-1, 64, 64, 1])\n",
    "\n",
    "print(x_image.shape)\n",
    "\n",
    "# Create 1st Convolutional and Pooling Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "# Create 2nd Convolutional and Pooling Layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "# Create 3rd Convolutional and Pooling Layer\n",
    "W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "b_conv3 = bias_variable([128])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# 1st Fully Connected Layer\n",
    "W_fc1 = weight_variable([128*8*8, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# Reshape the last convolutional layer output to connect with Fully Connected Layer\n",
    "h_pool2_flat = tf.reshape(h_pool3, [-1, 128*8*8])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Add the dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Output Layer\n",
    "W_fc2 = weight_variable([1024, 40])\n",
    "b_fc2 = bias_variable([40])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-36ed9d171268>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "0 Train accuracy 0.050167225 Validation accuracy 0.02\n",
      "1 Train accuracy 0.06688963 Validation accuracy 0.06\n",
      "2 Train accuracy 0.053511705 Validation accuracy 0.06\n",
      "3 Train accuracy 0.06354515 Validation accuracy 0.06\n",
      "4 Train accuracy 0.05685619 Validation accuracy 0.0\n",
      "5 Train accuracy 0.06354515 Validation accuracy 0.02\n",
      "6 Train accuracy 0.06688963 Validation accuracy 0.02\n",
      "7 Train accuracy 0.07692308 Validation accuracy 0.02\n",
      "8 Train accuracy 0.07023411 Validation accuracy 0.04\n",
      "9 Train accuracy 0.06020067 Validation accuracy 0.02\n",
      "10 Train accuracy 0.07023411 Validation accuracy 0.02\n",
      "11 Train accuracy 0.06354515 Validation accuracy 0.02\n",
      "12 Train accuracy 0.09030101 Validation accuracy 0.04\n",
      "13 Train accuracy 0.10702341 Validation accuracy 0.08\n",
      "14 Train accuracy 0.10367893 Validation accuracy 0.04\n",
      "15 Train accuracy 0.08695652 Validation accuracy 0.04\n",
      "16 Train accuracy 0.09698997 Validation accuracy 0.02\n",
      "17 Train accuracy 0.09030101 Validation accuracy 0.04\n",
      "18 Train accuracy 0.09364548 Validation accuracy 0.04\n",
      "19 Train accuracy 0.110367894 Validation accuracy 0.04\n",
      "20 Train accuracy 0.12040134 Validation accuracy 0.04\n",
      "21 Train accuracy 0.14381272 Validation accuracy 0.06\n",
      "22 Train accuracy 0.15050167 Validation accuracy 0.14\n",
      "23 Train accuracy 0.18394649 Validation accuracy 0.14\n",
      "24 Train accuracy 0.23411371 Validation accuracy 0.12\n",
      "25 Train accuracy 0.26086956 Validation accuracy 0.18\n",
      "26 Train accuracy 0.29431438 Validation accuracy 0.14\n",
      "27 Train accuracy 0.30769232 Validation accuracy 0.14\n",
      "28 Train accuracy 0.3043478 Validation accuracy 0.14\n",
      "29 Train accuracy 0.3110368 Validation accuracy 0.14\n",
      "30 Train accuracy 0.30769232 Validation accuracy 0.18\n",
      "31 Train accuracy 0.33779263 Validation accuracy 0.16\n",
      "32 Train accuracy 0.3645485 Validation accuracy 0.24\n",
      "33 Train accuracy 0.3846154 Validation accuracy 0.24\n",
      "34 Train accuracy 0.38795987 Validation accuracy 0.2\n",
      "35 Train accuracy 0.4180602 Validation accuracy 0.16\n",
      "36 Train accuracy 0.44147158 Validation accuracy 0.14\n",
      "37 Train accuracy 0.4916388 Validation accuracy 0.16\n",
      "38 Train accuracy 0.5117057 Validation accuracy 0.16\n",
      "39 Train accuracy 0.5117057 Validation accuracy 0.18\n",
      "40 Train accuracy 0.5451505 Validation accuracy 0.2\n",
      "41 Train accuracy 0.57525086 Validation accuracy 0.18\n",
      "42 Train accuracy 0.59197325 Validation accuracy 0.24\n",
      "43 Train accuracy 0.60535115 Validation accuracy 0.26\n",
      "44 Train accuracy 0.62541807 Validation accuracy 0.34\n",
      "45 Train accuracy 0.64882946 Validation accuracy 0.34\n",
      "46 Train accuracy 0.66220737 Validation accuracy 0.34\n",
      "47 Train accuracy 0.68561876 Validation accuracy 0.32\n",
      "48 Train accuracy 0.71571904 Validation accuracy 0.38\n",
      "49 Train accuracy 0.729097 Validation accuracy 0.38\n",
      "50 Train accuracy 0.7424749 Validation accuracy 0.4\n",
      "51 Train accuracy 0.77591974 Validation accuracy 0.46\n",
      "52 Train accuracy 0.7826087 Validation accuracy 0.48\n",
      "53 Train accuracy 0.7826087 Validation accuracy 0.56\n",
      "54 Train accuracy 0.78929764 Validation accuracy 0.54\n",
      "55 Train accuracy 0.8060201 Validation accuracy 0.54\n",
      "56 Train accuracy 0.8060201 Validation accuracy 0.54\n",
      "57 Train accuracy 0.819398 Validation accuracy 0.56\n",
      "58 Train accuracy 0.8327759 Validation accuracy 0.56\n",
      "59 Train accuracy 0.8327759 Validation accuracy 0.54\n",
      "60 Train accuracy 0.8528428 Validation accuracy 0.56\n",
      "61 Train accuracy 0.8528428 Validation accuracy 0.48\n",
      "62 Train accuracy 0.8662207 Validation accuracy 0.48\n",
      "63 Train accuracy 0.8762542 Validation accuracy 0.54\n",
      "64 Train accuracy 0.88294315 Validation accuracy 0.54\n",
      "65 Train accuracy 0.8896321 Validation accuracy 0.58\n",
      "66 Train accuracy 0.8896321 Validation accuracy 0.6\n",
      "67 Train accuracy 0.90301 Validation accuracy 0.62\n",
      "68 Train accuracy 0.89966553 Validation accuracy 0.62\n",
      "69 Train accuracy 0.90301 Validation accuracy 0.64\n",
      "70 Train accuracy 0.9230769 Validation accuracy 0.66\n",
      "71 Train accuracy 0.9230769 Validation accuracy 0.7\n",
      "72 Train accuracy 0.9230769 Validation accuracy 0.68\n",
      "73 Train accuracy 0.9230769 Validation accuracy 0.7\n",
      "74 Train accuracy 0.9297659 Validation accuracy 0.7\n",
      "75 Train accuracy 0.9397993 Validation accuracy 0.72\n",
      "76 Train accuracy 0.9431438 Validation accuracy 0.7\n",
      "77 Train accuracy 0.9498328 Validation accuracy 0.7\n",
      "78 Train accuracy 0.95652175 Validation accuracy 0.7\n",
      "79 Train accuracy 0.95652175 Validation accuracy 0.7\n",
      "80 Train accuracy 0.95652175 Validation accuracy 0.7\n",
      "81 Train accuracy 0.95652175 Validation accuracy 0.7\n",
      "82 Train accuracy 0.9632107 Validation accuracy 0.72\n",
      "83 Train accuracy 0.9632107 Validation accuracy 0.72\n",
      "84 Train accuracy 0.9665552 Validation accuracy 0.72\n",
      "85 Train accuracy 0.9665552 Validation accuracy 0.74\n",
      "86 Train accuracy 0.9665552 Validation accuracy 0.72\n",
      "87 Train accuracy 0.96989965 Validation accuracy 0.72\n",
      "88 Train accuracy 0.96989965 Validation accuracy 0.72\n",
      "89 Train accuracy 0.9765886 Validation accuracy 0.72\n",
      "90 Train accuracy 0.9765886 Validation accuracy 0.74\n",
      "91 Train accuracy 0.9765886 Validation accuracy 0.76\n",
      "92 Train accuracy 0.9765886 Validation accuracy 0.76\n",
      "93 Train accuracy 0.9799331 Validation accuracy 0.8\n",
      "94 Train accuracy 0.9799331 Validation accuracy 0.8\n",
      "95 Train accuracy 0.9832776 Validation accuracy 0.8\n",
      "96 Train accuracy 0.9832776 Validation accuracy 0.84\n",
      "97 Train accuracy 0.9832776 Validation accuracy 0.84\n",
      "98 Train accuracy 0.9866221 Validation accuracy 0.84\n",
      "99 Train accuracy 0.9866221 Validation accuracy 0.84\n"
     ]
    }
   ],
   "source": [
    "# Network base of Computation\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y_conv))\n",
    "training_op  = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# Prediction Measures\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Mention about the number of epochs training has to happen\n",
    "#epochs = 1100\n",
    "\n",
    "saver = tf.train. Saver()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict = {x : images_DataTraining, y_:labels_DataTraining, keep_prob : 0.5})\n",
    "        acc_train = accuracy.eval(feed_dict={x : images_DataTraining, y_:labels_DataTraining, keep_prob : 1.0})\n",
    "        acc_validation = accuracy.eval(feed_dict={x : images_DataValidation, y_:labels_DataValidation, keep_prob : 1.0})\n",
    "        print(epoch, \"Train accuracy\", acc_train, \"Validation accuracy\", acc_validation)\n",
    "    save_path = saver.save(sess, \"./my_model_find.ckpt\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_find.ckpt\n",
      "Testing accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_find.ckpt\")\n",
    "    acc_testing = accuracy.eval(feed_dict={x : images_DataTesting, y_:labels_DataTesting, keep_prob : 1})\n",
    "    print(\"Testing accuracy\", acc_testing)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
